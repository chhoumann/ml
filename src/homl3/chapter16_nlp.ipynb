{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "os.environ[\"KERAS_BACKEND\"] = \"torch\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "shakespeare_url = \"https://homl.info/shakespeare\"\n",
    "filepath = keras.utils.get_file(\"shakespeare.txt\", shakespeare_url)\n",
    "with open(filepath) as f:\n",
    "    shakespeare_text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n"
     ]
    }
   ],
   "source": [
    "print(shakespeare_text[:80])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-22 11:57:03.762442: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-08-22 11:57:03.771522: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-08-22 11:57:03.785078: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-08-22 11:57:03.788897: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-08-22 11:57:03.802302: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-08-22 11:57:04.549360: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1724320625.004357   25555 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-08-22 11:57:05.005608: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2343] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Map all characters to an integer, starting at 2.\n",
    "TextVectorization reserves 0 for padding tokens and 1 for unknown characters.\n",
    "\"\"\"\n",
    "text_vec_layer = keras.layers.TextVectorization(split=\"character\", standardize=\"lower\")\n",
    "text_vec_layer.adapt([shakespeare_text])\n",
    "encoded = text_vec_layer([shakespeare_text])[0].cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded = torch.tensor(encoded, dtype=torch.long) - 2  # don't need tokens 0 and 1\n",
    "n_tokens = text_vec_layer.vocabulary_size() - 2 # number of distinct chars\n",
    "dataset_size = len(encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10: 100%|██████████| 981/981 [00:26<00:00, 37.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Train Loss: 1.9607, Val Loss: 1.5598\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10: 100%|██████████| 981/981 [00:25<00:00, 38.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10, Train Loss: 1.4842, Val Loss: 1.4367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10: 100%|██████████| 981/981 [00:25<00:00, 38.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10, Train Loss: 1.4143, Val Loss: 1.3965\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10: 100%|██████████| 981/981 [00:25<00:00, 38.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10, Train Loss: 1.3849, Val Loss: 1.3753\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10: 100%|██████████| 981/981 [00:25<00:00, 38.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10, Train Loss: 1.3679, Val Loss: 1.3618\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10: 100%|██████████| 981/981 [00:25<00:00, 38.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10, Train Loss: 1.3566, Val Loss: 1.3526\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10: 100%|██████████| 981/981 [00:25<00:00, 38.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10, Train Loss: 1.3484, Val Loss: 1.3459\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10: 100%|██████████| 981/981 [00:25<00:00, 38.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10, Train Loss: 1.3423, Val Loss: 1.3403\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/10: 100%|██████████| 981/981 [00:25<00:00, 38.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10, Train Loss: 1.3373, Val Loss: 1.3357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|██████████| 981/981 [00:25<00:00, 38.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10, Train Loss: 1.3333, Val Loss: 1.3321\n"
     ]
    }
   ],
   "source": [
    "# Convert the entire dataset to a single tensor of sequences\n",
    "sequence_length = 100\n",
    "stride = 1\n",
    "sequences = encoded.unfold(0, sequence_length + 1, stride)\n",
    "\n",
    "# Split the data\n",
    "train_size = int(0.9 * len(sequences))\n",
    "val_size = int(0.05 * len(sequences))\n",
    "test_size = len(sequences) - train_size - val_size\n",
    "train_data, val_data, test_data = torch.utils.data.random_split(sequences, [train_size, val_size, test_size])\n",
    "\n",
    "# Create DataLoaders\n",
    "batch_size = 1024\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True, pin_memory=True, num_workers=4)\n",
    "val_loader = DataLoader(val_data, batch_size=batch_size, shuffle=False, pin_memory=True, num_workers=4)\n",
    "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False, pin_memory=True, num_workers=4)\n",
    "\n",
    "# Define the model\n",
    "class ShakespeareModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.gru = nn.GRU(embedding_dim, hidden_dim, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, vocab_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        embedded = self.embedding(x)\n",
    "        output, _ = self.gru(embedded)\n",
    "        return self.fc(output)\n",
    "\n",
    "# Initialize the model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = ShakespeareModel(n_tokens, embedding_dim=16, hidden_dim=128).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\"):\n",
    "        inputs, targets = batch[:, :-1].to(device), batch[:, 1:].to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs.view(-1, n_tokens), targets.view(-1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            inputs, targets = batch[:, :-1].to(device), batch[:, 1:].to(device)\n",
    "            outputs = model(inputs)\n",
    "            val_loss += criterion(outputs.view(-1, n_tokens), targets.view(-1)).item()\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {total_loss/len(train_loader):.4f}, Val Loss: {val_loss/len(val_loader):.4f}\")\n",
    "\n",
    "torch.save(model.state_dict(), \"shakespeare_model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "to be or not to be here,\n",
      "i repent the clifford of a bah what flies,\n",
      "that was he look their blood, mark me the senately to be now?\n",
      "\n",
      "prospero:\n",
      "they be the measure so sure:\n",
      "that last she hath as it cannot be help,\n",
      "with this grave bole you that stay and brawn he fall,\n",
      "i understand a princes, all the love of my devil\n",
      "a man of time again to she were sweet man;\n",
      "it is with the duke of york water repetly forth to be dist.\n",
      "\n",
      "claudio:\n",
      "i spoil the seat mourn struck'd\n",
      "to have bearing of a humble and to be book and look on.\n",
      "\n",
      "lady anne:\n",
      "what, mistress, have stand on the seas-\n",
      "thy ready the first court; let me so, the seirs.\n",
      "\n",
      "king richard iii:\n",
      "pain in his love, and the commons:\n",
      "the remembrace that she is the pale,\n",
      "and see the courses in your parquity\n",
      "is thy power and may seem on the gentleman:\n",
      "how most be so coming well of you.\n",
      "\n",
      "henry bolingbroke:\n",
      "i take the mother shall hear his prince hath stay piece\n",
      "with my widows come not a part and discipler:\n",
      "i here call down the blood is the rest\n",
      "in slave and gone, good even us, \n"
     ]
    }
   ],
   "source": [
    "def generate_text(model, start_text, num_generate=50, temperature=1.0):\n",
    "    # Convert start text to tensor\n",
    "    input_sequence = text_vec_layer([start_text.lower()])[0].cpu().numpy() - 2\n",
    "    input_sequence = torch.tensor(input_sequence, dtype=torch.long).unsqueeze(0).to(device)\n",
    "\n",
    "    model.eval()\n",
    "    generated_text = start_text\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for _ in range(num_generate):\n",
    "            # Get the last 'sequence_length' characters\n",
    "            input_sequence = input_sequence[:, -sequence_length:]\n",
    "            \n",
    "            # Generate prediction\n",
    "            output = model(input_sequence)\n",
    "            \n",
    "            # Apply temperature\n",
    "            output = output[:, -1, :] / temperature\n",
    "            probabilities = torch.nn.functional.softmax(output, dim=-1)\n",
    "            \n",
    "            # Sample from the distribution\n",
    "            next_char_index = torch.multinomial(probabilities, 1).item()\n",
    "            \n",
    "            # Convert back to character and append to generated text\n",
    "            next_char = text_vec_layer.get_vocabulary()[next_char_index + 2]  # +2 because we subtracted 2 earlier\n",
    "            generated_text += next_char\n",
    "            \n",
    "            # Update input sequence\n",
    "            input_sequence = torch.cat([input_sequence, torch.tensor([[next_char_index]], device=device)], dim=1)\n",
    "    \n",
    "    return generated_text\n",
    "\n",
    "# Load the trained model\n",
    "model.load_state_dict(torch.load(\"shakespeare_model.pth\"))\n",
    "model.to(device)\n",
    "\n",
    "# Generate text\n",
    "start_text = \"to be or not to b\"\n",
    "generated_text = generate_text(model, start_text, num_generate=1000, temperature=0.7)\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "We'll turn the long sequence into a dataset of windows that we can use to train a sequence-to-sequence RNN.\n",
    "Targets are similar to the inputs, but shifted by one time step into the 'future'.\n",
    "\n",
    "Example:\n",
    "One sample may be a sequence of character IDs representing the text \"to be or not to b\"\n",
    "And the corresponding target would be a sequence of character IDs representing the text \"o be or not to be\"\n",
    "\"\"\"\n",
    "\n",
    "def to_dataset(sequence, length, shuffle=False, seed=None, batch_size=32):\n",
    "    \"\"\"\n",
    "    Convert a sequence into a TensorFlow dataset of windowed samples for sequence-to-sequence training.\n",
    "\n",
    "    Args:\n",
    "        sequence (tf.Tensor): The input sequence to be windowed.\n",
    "        length (int): The length of each window (excluding the target token).\n",
    "        shuffle (bool, optional): Whether to shuffle the dataset. Defaults to False.\n",
    "        seed (int, optional): Random seed for shuffling. Defaults to None.\n",
    "        batch_size (int, optional): The batch size for the dataset. Defaults to 32.\n",
    "\n",
    "    Returns:\n",
    "        tf.data.Dataset: A dataset of windowed samples, where each sample is a tuple (input_window, target_window).\n",
    "                         The input_window is of shape (batch_size, length) and the target_window is of shape (batch_size, length).\n",
    "                         The target_window is shifted one step ahead of the input_window.\n",
    "\n",
    "    The function performs the following steps:\n",
    "    1. Creates a dataset from the input sequence.\n",
    "    2. Windows the dataset into overlapping sequences of length + 1, as we need the next character for the target.\n",
    "    3. Optionally shuffles the dataset.\n",
    "    4. Batches the dataset.\n",
    "    5. Maps the windowed sequences into input-target pairs.\n",
    "    6. Prefetches one batch to optimize performance.\n",
    "    \"\"\"\n",
    "    ds = tf.data.Dataset.from_tensor_slices(sequence)\n",
    "    ds = ds.window(length + 1, shift=1, drop_remainder=True)\n",
    "    ds = ds.flat_map(lambda window_ds: window_ds.batch(length + 1))\n",
    "    if shuffle:\n",
    "        ds = ds.shuffle(buffer_size=100_000, seed=seed)\n",
    "    ds = ds.batch(batch_size)\n",
    "    return ds.map(lambda window: (window[:, :-1], window[:, 1:])).prefetch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare dataset. Roughly: 90% train, 5% valid, 5% test.\n",
    "length = 100\n",
    "tf.random.set_seed(42)\n",
    "train_set = to_dataset(encoded[:1_000_000], length=length, shuffle=True, seed=42)\n",
    "valid_set = to_dataset(encoded[1_000_000:1_060_000], length=length)\n",
    "test_set = to_dataset(encoded[1_060_000:], length=length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(input_dim=n_tokens, output_dim=16),\n",
    "    tf.keras.layers.GRU(128, return_sequences=True),\n",
    "    tf.keras.layers.Dense(n_tokens, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"nadam\", metrics=[\"accuracy\"])\n",
    "model_ckpt = tf.keras.callbacks.ModelCheckpoint(\"my_shakespeare_model.keras\", monitor=\"val_accuracy\", save_best_only=True)\n",
    "history = model.fit(train_set, validation_data=valid_set, epochs=10, callbacks=[model_ckpt])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NMT - English to Spanish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip\"\n",
    "path = keras.utils.get_file(\"spa-eng.zip\", origin=url, extract=True, cache_dir=\"datasets\")\n",
    "text = (Path(path).parent / \"spa-eng\" / \"spa.txt\").read_text(encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = text.replace(\"¡\", \"\").replace(\"¿\", \"\")\n",
    "pairs = [line.split(\"\\t\") for line in text.splitlines() if len(line) >= 3]\n",
    "np.random.shuffle(pairs)\n",
    "sentences_en, sentences_es = zip(*pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "She is kissing him. => Ella lo está besando.\n",
      "I have a life. => Tengo una vida.\n",
      "Let me see your prescription. => Déjame ver tu receta médica.\n"
     ]
    }
   ],
   "source": [
    "for i in range(3):\n",
    "    print(sentences_en[i], \"=>\", sentences_es[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-29 13:31:54.050813: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-08-29 13:31:54.128562: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-08-29 13:31:54.197004: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-08-29 13:31:54.214973: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-08-29 13:31:54.353694: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-08-29 13:31:55.398880: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1724931115.972810    5180 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-08-29 13:31:55.979154: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2343] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 1_000 # this is small because the training set is small & using a small value speeds up training. SOTA models uses a lot more (e.g. 30k), uses larger training sets, and larger models.\n",
    "max_length = 50 # all sentences in this dataset have a max of 50 words.\n",
    "text_vec_layer_en = keras.layers.TextVectorization(\n",
    "    max_tokens=vocab_size,\n",
    "    output_sequence_length=max_length,\n",
    ")\n",
    "text_vec_layer_es = keras.layers.TextVectorization(\n",
    "    max_tokens=vocab_size,\n",
    "    output_sequence_length=max_length,\n",
    ")\n",
    "\n",
    "text_vec_layer_en.adapt(sentences_en)\n",
    "text_vec_layer_es.adapt([f\"startofseq {text} endofseq\" for text in sentences_es]) # adding start and end tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 100000\n",
      "Validation set size: 18964\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader, random_split\n",
    "\n",
    "# Convert sentences to tensors\n",
    "sentences_en_tensor = torch.tensor(text_vec_layer_en(sentences_en).cpu().numpy())\n",
    "\n",
    "# Prepare decoder inputs (Spanish sentences with SOS prefix)\n",
    "decoder_inputs = torch.tensor(text_vec_layer_es([f\"startofseq {text}\" for text in sentences_es]).cpu().numpy())\n",
    "\n",
    "# Prepare targets (Spanish sentences with EOS suffix)\n",
    "targets = torch.tensor(text_vec_layer_es([f\"{text} endofseq\" for text in sentences_es]).cpu().numpy())\n",
    "\n",
    "# Create a TensorDataset with three elements: encoder input, decoder input, and target\n",
    "dataset = TensorDataset(sentences_en_tensor, decoder_inputs, targets)\n",
    "\n",
    "# Split the dataset\n",
    "train_size = min(100000, len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "# Create DataLoaders\n",
    "batch_size = 32  # You can adjust this as needed\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "\n",
    "print(f\"Training set size: {len(train_dataset)}\")\n",
    "print(f\"Validation set size: {len(val_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EncoderDecoder(\n",
      "  (encoder): LSTM(256, 512, num_layers=2, dropout=0.5)\n",
      "  (decoder): LSTM(256, 512, num_layers=2, dropout=0.5)\n",
      "  (input_embedding): Embedding(1000, 256)\n",
      "  (output_embedding): Embedding(1000, 256)\n",
      "  (fc_out): Linear(in_features=512, out_features=1000, bias=True)\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class EncoderDecoder(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, emb_dim, hid_dim, n_layers, dropout):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.encoder = nn.LSTM(emb_dim, hid_dim, n_layers, dropout=dropout)\n",
    "        self.decoder = nn.LSTM(emb_dim, hid_dim, n_layers, dropout=dropout)\n",
    "        \n",
    "        self.input_embedding = nn.Embedding(input_dim, emb_dim)\n",
    "        self.output_embedding = nn.Embedding(output_dim, emb_dim)\n",
    "        \n",
    "        self.fc_out = nn.Linear(hid_dim, output_dim)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, src, trg, teacher_forcing_ratio=0.5):\n",
    "        batch_size = src.shape[1]\n",
    "        trg_len = trg.shape[0]\n",
    "        trg_vocab_size = self.fc_out.out_features\n",
    "        \n",
    "        outputs = torch.zeros(trg_len, batch_size, trg_vocab_size).to(src.device)\n",
    "        \n",
    "        # Encoder\n",
    "        embedded_src = self.dropout(self.input_embedding(src))\n",
    "        _, (hidden, cell) = self.encoder(embedded_src)\n",
    "        \n",
    "        # Decoder\n",
    "        input = trg[0,:]\n",
    "        for t in range(1, trg_len):\n",
    "            embedded_input = self.dropout(self.output_embedding(input))\n",
    "            output, (hidden, cell) = self.decoder(embedded_input.unsqueeze(0), (hidden, cell))\n",
    "            prediction = self.fc_out(output.squeeze(0))\n",
    "            outputs[t] = prediction\n",
    "            teacher_force = torch.rand(1).item() < teacher_forcing_ratio\n",
    "            top1 = prediction.argmax(1)\n",
    "            input = trg[t] if teacher_force else top1\n",
    "        \n",
    "        return outputs\n",
    "\n",
    "# Instantiate the model\n",
    "input_dim = vocab_size  # size of input vocabulary\n",
    "output_dim = vocab_size  # size of output vocabulary\n",
    "emb_dim = 256  # embedding dimension\n",
    "hid_dim = 512  # hidden dimension\n",
    "n_layers = 2  # number of LSTM layers\n",
    "dropout = 0.5\n",
    "\n",
    "model = EncoderDecoder(input_dim, output_dim, emb_dim, hid_dim, n_layers, dropout)\n",
    "print(model)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=0)  # Assuming 0 is the padding index\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "\n",
    "# Move model to GPU if available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10: 100%|██████████| 3125/3125 [04:20<00:00, 11.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Train Loss: 4.6693, Val Loss: 4.6486\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10: 100%|██████████| 3125/3125 [04:24<00:00, 11.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10, Train Loss: 4.6558, Val Loss: 4.6468\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10: 100%|██████████| 3125/3125 [04:16<00:00, 12.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10, Train Loss: 4.6543, Val Loss: 4.6450\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10: 100%|██████████| 3125/3125 [04:14<00:00, 12.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10, Train Loss: 4.6530, Val Loss: 4.6441\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10: 100%|██████████| 3125/3125 [04:16<00:00, 12.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10, Train Loss: 4.6530, Val Loss: 4.6437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10: 100%|██████████| 3125/3125 [04:26<00:00, 11.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10, Train Loss: 4.6528, Val Loss: 4.6441\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10: 100%|██████████| 3125/3125 [04:22<00:00, 11.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10, Train Loss: 4.6522, Val Loss: 4.6431\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10: 100%|██████████| 3125/3125 [04:24<00:00, 11.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10, Train Loss: 4.6515, Val Loss: 4.6435\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/10: 100%|██████████| 3125/3125 [04:05<00:00, 12.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10, Train Loss: 4.6520, Val Loss: 4.6436\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|██████████| 3125/3125 [04:38<00:00, 11.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10, Train Loss: 4.6519, Val Loss: 4.6424\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    \n",
    "    for batch in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\"):\n",
    "        src, trg_input, trg_output = [t.to(device).transpose(0, 1) for t in batch]\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        output = model(src, trg_input)\n",
    "        \n",
    "        # Reshape output and target, ensuring same batch size\n",
    "        output = output[1:].reshape(-1, output.shape[-1])\n",
    "        trg_output = trg_output.transpose(0, 1)[1:].reshape(-1)\n",
    "        \n",
    "        # Truncate to the minimum length\n",
    "        min_len = min(output.size(0), trg_output.size(0))\n",
    "        output = output[:min_len]\n",
    "        trg_output = trg_output[:min_len]\n",
    "        \n",
    "        loss = criterion(output, trg_output)\n",
    "        loss.backward()\n",
    "        \n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            src, trg_input, trg_output = [t.to(device).transpose(0, 1) for t in batch]\n",
    "            output = model(src, trg_input, 0)  # Turn off teacher forcing\n",
    "            \n",
    "            # Reshape output and target, ensuring same batch size\n",
    "            output = output[1:].reshape(-1, output.shape[-1])\n",
    "            trg_output = trg_output.transpose(0, 1)[1:].reshape(-1)\n",
    "            \n",
    "            # Truncate to the minimum length\n",
    "            min_len = min(output.size(0), trg_output.size(0))\n",
    "            output = output[:min_len]\n",
    "            trg_output = trg_output[:min_len]\n",
    "            \n",
    "            val_loss += criterion(output, trg_output).item()\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {total_loss/len(train_loader):.4f}, Val Loss: {val_loss/len(val_loader):.4f}\")\n",
    "\n",
    "# Save the model\n",
    "torch.save(model.state_dict(), \"nmt_model.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
